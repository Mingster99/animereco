{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3e017f",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Model without factor models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4996234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca34d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "anime_df = pd.read_csv('assignment_2_data/assignment_2_anime.csv')\n",
    "test_df = pd.read_csv('assignment_2_data/assignment_2_ratings_test.csv')\n",
    "train_df = pd.read_csv('assignment_2_data/assignment_2_ratings_train.csv')\n",
    "\n",
    "anime_mean_ratings = train_df.groupby('anime_id')['rating'].mean()\n",
    "\n",
    "# filling the missing values in test_df with the average rating of each anime\n",
    "test_df['rating'] = test_df.apply(lambda row: anime_mean_ratings[row['anime_id']]\n",
    "                                                if pd.isnull(row['rating']) else row['rating'], axis=1)\n",
    "\n",
    "# Compute the mean rating for each user in the training set\n",
    "user_mean_ratings = train_df.groupby('user_id')['rating'].mean()\n",
    "\n",
    "# Predict the ratings for each user & anime in the test set\n",
    "predictions = []\n",
    "for i, row in test_df.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    anime_id = row['anime_id']\n",
    "    if user_id in user_mean_ratings:\n",
    "        predictions.append(user_mean_ratings[user_id])\n",
    "    else:\n",
    "        predictions.append(anime_mean_ratings[anime_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf85e04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8632767692499541\n",
      "RMSE: 1.365018962963502\n"
     ]
    }
   ],
   "source": [
    "# Compute the MSE\n",
    "mse = ((test_df['rating'] - predictions) ** 2).mean()\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5884e61",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc8fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b40599",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df = pd.read_csv('assignment_2_data/assignment_2_anime.csv')\n",
    "test_df = pd.read_csv('assignment_2_data/assignment_2_ratings_test.csv')\n",
    "train_df = pd.read_csv('assignment_2_data/assignment_2_ratings_train.csv')\n",
    "\n",
    "test_rating = test_df['rating']\n",
    "test_df_user = test_df[['user_id', 'anime_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97471a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rating scale based on anime review scores 1-10\n",
    "reader = Reader(rating_scale=(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3115b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using surprise library to alter data into usable format for SVD  \n",
    "train_data = Dataset.load_from_df(train_df[['user_id', 'anime_id', 'rating']], reader)\n",
    "test_data = Dataset.load_from_df(test_df[['user_id', 'anime_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88108ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "trainset, valset = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402601a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fe1ba6622e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model using SVD algorithm\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26bb957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1704\n",
      "MSE: 1.3698\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_predictions = algo.test(valset)\n",
    "val_rmse = accuracy.rmse(val_predictions)\n",
    "val_mse = accuracy.mse(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1694980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1714\n",
      "MSE: 1.3721\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_predictions = algo.test(test_data.build_full_trainset().build_testset())\n",
    "test_rmse = accuracy.rmse(test_predictions)\n",
    "test_mse = accuracy.mse(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd3939a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE score: 1.1703766064543302\n",
      "Test RMSE score: 1.1713597838288727\n",
      "Validation MSE score: 1.369781400935554\n",
      "Test MSE score: 1.3720837431716233\n"
     ]
    }
   ],
   "source": [
    "# Print the RMSE score for validation and test sets\n",
    "print(\"Validation RMSE score:\", val_rmse)\n",
    "print(\"Test RMSE score:\", test_rmse)\n",
    "\n",
    "# Print the MSE score for validation and test sets\n",
    "print(\"Validation MSE score:\", val_mse)\n",
    "print(\"Test MSE score:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f27501",
   "metadata": {},
   "source": [
    "# Matrix Factorisation Model (Runs very slowly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20093839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import surprise\n",
    "from surprise import SVD, Reader, Dataset\n",
    "import math\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9dc980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anime_df = pd.read_csv('assignment_2_data/assignment_2_anime.csv')\n",
    "test_df = pd.read_csv('assignment_2_data/assignment_2_ratings_test.csv')\n",
    "train_df = pd.read_csv('assignment_2_data/assignment_2_ratings_train.csv')\n",
    "train_df, train_test_df = train_test_split(train_df, test_size = 0.7, random_state = 42)\n",
    "\n",
    "test_rating = test_df['rating']\n",
    "test_df_user = test_df[['user_id', 'anime_id']]\n",
    "\n",
    "train_df = train_df.groupby(['user_id', 'anime_id']).mean().reset_index()\n",
    "ratings_matrix = train_df.pivot(index='user_id', columns='anime_id', values='rating')\n",
    "\n",
    "anime_df['genre'] = anime_df['genre'].str.split(', ')\n",
    "\n",
    "anime_df =anime_df.sort_values(by = ['anime_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8e4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df.loc[anime_df['genre'].isnull(),'genre'] = anime_df.loc[anime_df['genre'].isnull(),'genre'].apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14e6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MultiLabelBinarizer()\n",
    "encoded_genres = encoder.fit_transform(anime_df['genre'])\n",
    "\n",
    "encoded_new = encoded_genres[anime_df['anime_id'].isin(ratings_matrix.keys())]\n",
    "encoded_new = pd.DataFrame(encoded_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a051c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(ratings, users, genres, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    ratings: Ratings Matrix\n",
    "    users: User Matrix\n",
    "    genres: Genres Matrix\n",
    "    K: Number of Genres\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter\n",
    "    '''\n",
    "\n",
    "    for step in range(steps):\n",
    "      for i in ratings.keys(): # Each anime film\n",
    "        for j in ratings[i].keys(): # Each user\n",
    "          if math.isnan(ratings[i][j]) == False: # check if there is a rating\n",
    "            i_loc = np.where(ratings.keys() == i)[0][0] # locating the anime index in the ratings matrix\n",
    "            j_loc = np.where(ratings[i].keys() == j)[0][0] # locating the user index in the ratings matrix\n",
    "            \n",
    "            # calculate the error\n",
    "            eij = ratings[i][j] - np.dot(users[j_loc,:], genres.iloc[i_loc])\n",
    "\n",
    "            for k in range(K):\n",
    "                # calculate gradient with a and beta parameter\n",
    "                users[j_loc][k] = users[j_loc][k] + alpha * (2 * eij * genres.iloc[i_loc][k] - beta * users[j_loc][k])\n",
    "                genres.iloc[i_loc][k] = genres.iloc[i_loc][k] + alpha * (2 * eij * users[j_loc][k] - beta * genres.iloc[i_loc][k])\n",
    "\n",
    "      e = 0\n",
    "\n",
    "      for i in ratings.keys(): # Each anime film\n",
    "        for j in ratings[i].keys(): # Each user\n",
    "\n",
    "          if math.isnan(ratings[i][j]) == False: # check if there is a rating\n",
    "            i_loc = np.where(ratings.keys() == i)[0][0] # locating the anime index in the ratings matrix\n",
    "            j_loc = np.where(ratings[i].keys() == j)[0][0] # locating the user index in the ratings matrix\n",
    "\n",
    "            # Calculating the error\n",
    "            e = e + pow(ratings[i][j] - np.dot(users[j_loc,:],genres.iloc[i_loc]), 2)\n",
    "            \n",
    "            # summing the error\n",
    "            for k in range(K):\n",
    "              e = e + (beta/2) * (pow(users[j_loc][k],2) + pow(genres.iloc[i_loc][k],2))\n",
    "      \n",
    "      # stopping threshold\n",
    "      if e < 0.001:\n",
    "\n",
    "        break\n",
    "\n",
    "    return users, genres.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c85232f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m k \u001b[38;5;241m=\u001b[39m encoded_genres\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Number of genres\u001b[39;00m\n\u001b[1;32m      6\u001b[0m users \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_user,k)) \u001b[38;5;66;03m# User feature matrix\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m nP, nQ \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mmatrix_factorization\u001b[0;34m(ratings, users, genres, K, steps, alpha, beta)\u001b[0m\n\u001b[1;32m     17\u001b[0m j_loc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(ratings[i]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m==\u001b[39m j)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# locating the user index in the ratings matrix\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calculate the error\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m eij \u001b[38;5;241m=\u001b[39m ratings[i][j] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(users[j_loc,:], \u001b[43mgenres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[i_loc])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# calculate gradient with a and beta parameter\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     users[j_loc][k] \u001b[38;5;241m=\u001b[39m users[j_loc][k] \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m eij \u001b[38;5;241m*\u001b[39m genres\u001b[38;5;241m.\u001b[39miloc[i_loc][k] \u001b[38;5;241m-\u001b[39m beta \u001b[38;5;241m*\u001b[39m users[j_loc][k])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:139\u001b[0m, in \u001b[0;36mIndexingMixin.iloc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexingMixin\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    Mixin for adding .loc/.iloc/.at/.iat to Dataframes and Series.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miloc\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _iLocIndexer:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m        Purely integer-location based indexing for selection by position.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m        2  1000  3000\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _iLocIndexer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_user = len(ratings_matrix)\n",
    "num_anime = len(ratings_matrix[1])\n",
    "\n",
    "k = encoded_genres.shape[1] # Number of genres\n",
    "\n",
    "users = np.zeros((num_user,k)) # User feature matrix\n",
    "\n",
    "nP, nQ = matrix_factorization(ratings_matrix, users, encoded_new, k, steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nR = np.dot(nP, nQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
